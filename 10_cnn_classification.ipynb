{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Practice: MNIST Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch Version: 1.5.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Pytorch Version:' , torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "\n",
      "data shape:  (60000, 28, 28)\n",
      "label shape:  (60000,)\n",
      "\n",
      "Peek at some training pictures:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 50\n",
    "EPOCH = 1\n",
    "DOWNLOAD_MINIST = False\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(), # each pixel is compressed from (0,255) to (0,1)\n",
    "    download=DOWNLOAD_MINIST\n",
    ")\n",
    "\n",
    "print('Training data: \\n')\n",
    "print('data shape: ', train_data.data.numpy().shape)\n",
    "print('label shape: ', train_data.targets.numpy().shape)\n",
    "\n",
    "print('\\nPeek at some training pictures:')\n",
    "plt.imshow(train_data.data.numpy()[0], cmap='gray')\n",
    "plt.title('%i' % train_data.targets[0])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(train_data.data.numpy()[1], cmap='gray')\n",
    "plt.title('%i' % train_data.targets[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test data: \n",
      "\n",
      "data shape:  (10000, 28, 28)\n",
      "label size:  (10000,)\n",
      "\n",
      "Test data used in this notebook: \n",
      "\n",
      "data shape:  (2000, 1, 28, 28)\n",
      "label shape:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "test_data = torchvision.datasets.MNIST(root='./mnist',train=False)\n",
    "\n",
    "# /255 -> compress each pixel from (0, 255) to (0,1)\n",
    "test_x = Variable(torch.unsqueeze(test_data.data, dim=1)).type(torch.FloatTensor)[:2000]/255\n",
    "test_y = test_data.targets[:2000]\n",
    "\n",
    "print('Original test data: \\n')\n",
    "print('data shape: ', test_data.data.numpy().shape)\n",
    "print('label size: ', test_data.targets.numpy().shape)\n",
    "\n",
    "print('\\nTest data used in this notebook: \\n')\n",
    "print('data shape: ', test_x.data.numpy().shape)\n",
    "print('label shape: ', test_y.data.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batched data shape: (50, 1, 28, 28)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d( # apply 2D convolution\n",
    "                in_channels=1, # 28x28 black and white images, which only contain 1 channel\n",
    "                out_channels=16, # 16 filters to extract 16 features\n",
    "                kernel_size=5, # 5x5 filter\n",
    "                stride=1,\n",
    "                padding=2, # to maintain spatial size, padding = (kernel_size-stride)/2\n",
    "            ), # -> (16, 28, 28)\n",
    "            torch.nn.ReLU(), # -> (16, 28, 28)\n",
    "            torch.nn.MaxPool2d(kernel_size=2) # -> (16, 14, 14)\n",
    "        ) \n",
    "        \n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(16, 32, 5, 1, 2), # -> (32, 14, 14)\n",
    "            torch.nn.ReLU(), # -> (32, 14, 14)\n",
    "            torch.nn.MaxPool2d(2) # -> (32, 7, 7)\n",
    "        )\n",
    "        \n",
    "        self.score = torch.nn.Linear(32*7*7, 10) # we have 10 labels from 0 to 9\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # -> (batch, 32, 14, 14)\n",
    "        x = self.conv2(x) # -> (batch, 32, 7, 7)\n",
    "        x = x.view(x.size(0), -1) # -> (batch, 32*7*7)\n",
    "        scores = self.score(x) # -> (batch, 10)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (score): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.3016 | test accuracy: 0.15\n",
      "Epoch:  0 | train loss: 0.2184 | test accuracy: 0.88\n",
      "Epoch:  0 | train loss: 0.2552 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.3305 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.1592 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.0903 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.1107 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.0418 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.1005 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.0608 | test accuracy: 0.98\n",
      "Epoch:  0 | train loss: 0.0744 | test accuracy: 0.98\n",
      "Epoch:  0 | train loss: 0.0582 | test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        batch_x = Variable(batch_x)\n",
    "        batch_y = Variable(batch_y)\n",
    "        \n",
    "        scores = cnn(batch_x)\n",
    "        loss = loss_fn(scores, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 60000 input images, batch_size = 50\n",
    "        # there are 60000/50 = 1200 steps\n",
    "        if step % 100 == 0: \n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  [7 2 1 0 4 1 4 9 5 9]\n",
      "true label:  [7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "# print 10 predictions from test data\n",
    "test_output = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "print('prediction: ', pred_y)\n",
    "print('true label: ', test_y[:10].numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
